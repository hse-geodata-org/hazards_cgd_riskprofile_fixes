{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b92d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4] Reading Excel: C:\\Users\\User\\Documents\\ЦГД\\Структура базы_v03.xlsx (sheet='Поля для дашборда') ...\n",
      "       Rows: 112; Columns: ['Группа полей', 'Поле шейпа (10 симв., латынь)', 'Псевдоним (понятный, русский)', 'Размерность исходных данных', 'Псевдоним в дашборде', 'Wildfire', 'Cold', 'Heat', 'Rain', 'Wind', 'Freez', 'Hail', 'Thunderstorm', 'Drought', 'Flood', 'Permafrost', 'количество знаков после запятой', 'комментарий']\n",
      "       Risk columns detected: 15\n",
      "\n",
      "[2/4] Feature dataset 'risk' -> 11 feature classes found\n",
      "\n",
      "[FC 1/11] KHMAO_hazHeat_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazHeat_MO\n",
      "       Matched risk column in Excel: 'Heat' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'ieMeanTot': 1, 'ieMeanLive': 1, 'ieMaxTot': 1, 'ieMaxLive': 1, 'itMeanTot': 1, 'itMeanLive': 1, 'iOverTot': 0, 'iOverLive': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 35 cols -> KHMAO_KHMAO_hazHeat_MO.csv\n",
      "[FC 2/11] KHMAO_hazardTemplate_MO -> skipped (template)\n",
      "\n",
      "[FC 3/11] KHMAO_hazCold_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazCold_MO\n",
      "       Matched risk column in Excel: 'Cold' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'ieMeanTot': 1, 'ieMeanLive': 1, 'ieMaxTot': 1, 'ieMaxLive': 1, 'itMeanTot': 1, 'itMeanLive': 1, 'iOverTot': 0, 'iOverLive': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rLiHA_ro': 0, 'rLF_ro': 0, 'rViHA_ro': 0, 'rVaR_ro': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 41 cols -> KHMAO_KHMAO_hazCold_MO.csv\n",
      "\n",
      "[FC 4/11] KHMAO_hazRain_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazRain_MO\n",
      "       Matched risk column in Excel: 'Rain' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'ieMeanTot': 1, 'ieMeanLive': 1, 'ieMaxTot': 1, 'ieMaxLive': 1, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 37 cols -> KHMAO_KHMAO_hazRain_MO.csv\n",
      "\n",
      "[FC 5/11] KHMAO_hazThunderstorm_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazThunderstorm_MO\n",
      "       Matched risk column in Excel: 'Thunderstorm' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hExpertTot': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rSiHA_fo': 0, 'rSF_fo': 0, 'rViHA_fo': 0, 'rVaR_fo': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 27 cols -> KHMAO_KHMAO_hazThunderstorm_MO.csv\n",
      "\n",
      "[FC 6/11] KHMAO_hazFreez5_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazFreez5_MO\n",
      "       Matched risk column in Excel: 'Freez' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 23 cols -> KHMAO_KHMAO_hazFreez5_MO.csv\n",
      "\n",
      "[FC 7/11] KHMAO_hazHail_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazHail_MO\n",
      "       Matched risk column in Excel: 'Hail' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 23 cols -> KHMAO_KHMAO_hazHail_MO.csv\n",
      "\n",
      "[FC 8/11] KHMAO_hazWind_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazWind_MO\n",
      "       Matched risk column in Excel: 'Wind' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'ieMeanTot': 1, 'ieMeanLive': 1, 'ieMaxTot': 1, 'ieMaxLive': 1, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rSiHA_fo': 0, 'rSF_fo': 0, 'rViHA_fo': 0, 'rVaR_fo': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 33 cols -> KHMAO_KHMAO_hazWind_MO.csv\n",
      "\n",
      "[FC 9/11] KHMAO_hazFlood_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazFlood_MO\n",
      "       Matched risk column in Excel: 'Flood' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'hNormTot': 2, 'hNormLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rLiHA_ro': 0, 'rLF_ro': 0, 'rViHA_ro': 0, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0}\n",
      "       ✔ Exported 22 rows, 21 cols -> KHMAO_KHMAO_hazFlood_MO.csv\n",
      "\n",
      "[FC 10/11] KHMAO_hazPermafrost_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazPermafrost_MO\n",
      "       Matched risk column in Excel: 'Permafrost' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'itMeanTot': 1, 'itMeanLive': 1, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rLiHA_ro': 0, 'rLF_ro': 0, 'rViHA_ro': 0, 'rVaR_ro': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 31 cols -> KHMAO_KHMAO_hazPermafrost_MO.csv\n",
      "\n",
      "[FC 11/11] KHMAO_hazWildfire_MO -> C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\\risk\\KHMAO_hazWildfire_MO\n",
      "       Matched risk column in Excel: 'Wildfire' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'itMeanTot': 1, 'itMeanLive': 1, 'feMeanTot': 0, 'feMeanLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hExpertTot': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rSiHA_fo': 0, 'rSF_fo': 0, 'rViHA_fo': 0, 'rVaR_fo': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 22 rows, 31 cols -> KHMAO_KHMAO_hazWildfire_MO.csv\n",
      "\n",
      "[3/4] Exported CSVs: 10\n",
      "[4/4] Output folder: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\risk_csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Export risk feature classes to CSV with per-field aliases and numeric transforms.\n",
    "\n",
    "For each FC in <gdb>\\risk:\n",
    "  - Map FC to a risk column in sheet 'Поля для дашборда'\n",
    "  - Keep rows where that risk column is non-empty; the cell is the TARGET ALIAS\n",
    "  - Read only those fields from the FC (no geometry)\n",
    "  - Per field:\n",
    "      * If Excel 'комментарий' cell is non-empty -> multiply by 100\n",
    "      * If field is iOverTot or iOverLive -> value = value*100 - 100\n",
    "      * Round to N decimals from Excel column 'количество знаков после запятой'\n",
    "  - Rename to alias and export CSV\n",
    "\n",
    "Requires: arcpy, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "# ========= CONFIGURE =========\n",
    "region     = \"Yakutia\"\n",
    "gdb_path   = r\"C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\Default.gdb\"\n",
    "RISKS_FDS  = \"risk\"\n",
    "EXCEL_PATH = r\"C:\\Users\\User\\Documents\\ЦГД\\Структура базы_v03.xlsx\"   # or the updated \"(1).xlsx\"\n",
    "SHEET_NAME = \"Поля для дашборда\"\n",
    "OUT_DIR    = os.path.join(os.path.dirname(gdb_path), \"risk_csv\")\n",
    "ENCODING   = \"utf-8-sig\"\n",
    "\n",
    "# Exact column headers (with robust fallbacks)\n",
    "FIELDNAME_HEADER   = \"Поле шейпа (10 симв., латынь)\"\n",
    "DECIMALS_HEADER    = \"количество знаков после запятой\"\n",
    "COMMENT_HEADER     = \"комментарий\"\n",
    "\n",
    "# ========= HELPERS =========\n",
    "def print_flush(*args, **kwargs):\n",
    "    print(*args, **kwargs); sys.stdout.flush()\n",
    "\n",
    "def secs(dt): return f\"{dt:.2f}s\"\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    return re.sub(r\"[_\\W]+\", \"\", str(s).strip().lower(), flags=re.UNICODE)\n",
    "\n",
    "def is_truthy_cell(v) -> bool:\n",
    "    if pd.isna(v): return False\n",
    "    if isinstance(v, (int, float)):\n",
    "        try: return float(v) != 0.0\n",
    "        except Exception: return True\n",
    "    s = str(v).strip()\n",
    "    return len(s) > 0 and s not in {\"0\", \"нет\", \"no\", \"false\", \"False\", \"-\"}\n",
    "\n",
    "def find_best_risk_column(fc_name: str, candidate_cols):\n",
    "    \"\"\"Exact (ci) → normalized equality → substring overlap.\"\"\"\n",
    "    fc_l = fc_name.strip()\n",
    "    fc_n = normalize(fc_l)\n",
    "\n",
    "    for c in candidate_cols:\n",
    "        if fc_l.lower() == str(c).strip().lower():\n",
    "            return c\n",
    "    for c in candidate_cols:\n",
    "        if fc_n == normalize(c):\n",
    "            return c\n",
    "    best, best_len = None, 0\n",
    "    for c in candidate_cols:\n",
    "        cn = normalize(c)\n",
    "        if fc_n in cn or cn in fc_n:\n",
    "            L = min(len(fc_n), len(cn))\n",
    "            if L > best_len:\n",
    "                best, best_len = c, L\n",
    "    return best\n",
    "\n",
    "def featureclass_to_df(fc_path: str, fields: list) -> pd.DataFrame:\n",
    "    \"\"\"Use SearchCursor so NULLs stay as None (avoids NumPy dtype issues).\"\"\"\n",
    "    if not fields:\n",
    "        return pd.DataFrame()\n",
    "    rows = []\n",
    "    with arcpy.da.SearchCursor(fc_path, fields) as cur:\n",
    "        for row in cur:\n",
    "            rows.append(row)\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=fields)\n",
    "    return pd.DataFrame.from_records(rows, columns=fields)\n",
    "\n",
    "# ========= READ EXCEL =========\n",
    "t0 = time.time()\n",
    "print_flush(f\"[1/4] Reading Excel: {EXCEL_PATH} (sheet='{SHEET_NAME}') ...\")\n",
    "df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME)\n",
    "print_flush(f\"       Rows: {len(df)}; Columns: {list(df.columns)}\")\n",
    "\n",
    "# Robust header resolution\n",
    "cols_lower = {str(c).strip().lower(): c for c in df.columns}\n",
    "\n",
    "def pick(colname, *fallbacks):\n",
    "    c = cols_lower.get(colname.strip().lower())\n",
    "    if c: return c\n",
    "    for fb in fallbacks:\n",
    "        cc = cols_lower.get(fb.strip().lower())\n",
    "        if cc: return cc\n",
    "    raise ValueError(f\"Не найден столбец: '{colname}' (с учетом возможных вариантов: {fallbacks})\")\n",
    "\n",
    "field_col    = cols_lower.get(FIELDNAME_HEADER.lower()) or pick(FIELDNAME_HEADER, \"название поля\", \"field_name_tot\", \"имя поля\")\n",
    "decimals_col = cols_lower.get(DECIMALS_HEADER.lower())  or pick(DECIMALS_HEADER, \"знаков после запятой\", \"decimal places\")\n",
    "comment_col  = cols_lower.get(COMMENT_HEADER.lower())   or pick(COMMENT_HEADER, \"коммент\", \"comment\")\n",
    "\n",
    "# Normalize core columns\n",
    "df[field_col]    = df[field_col].astype(str).str.strip()\n",
    "# decimals may be numeric or text; keep as-is for now\n",
    "# comment stays as-is; presence indicates x100\n",
    "\n",
    "# Risk columns are *everything else* (each cell holds the ALIAS to use)\n",
    "meta_cols = {field_col, decimals_col, comment_col}\n",
    "risk_cols_in_sheet = [c for c in df.columns if c not in meta_cols]\n",
    "if not risk_cols_in_sheet:\n",
    "    raise RuntimeError(\"В листе не обнаружены столбцы с рисками (кроме полей, знаков и комментариев).\")\n",
    "print_flush(f\"       Risk columns detected: {len(risk_cols_in_sheet)}\")\n",
    "\n",
    "# ========= SCAN GDB / EXPORT =========\n",
    "arcpy.env.workspace = os.path.join(gdb_path, RISKS_FDS)\n",
    "fcs = arcpy.ListFeatureClasses() or []\n",
    "print_flush(f\"\\n[2/4] Feature dataset '{RISKS_FDS}' -> {len(fcs)} feature classes found\")\n",
    "\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "exported = 0\n",
    "for idx, fc in enumerate(fcs, start=1):\n",
    "    if \"template\" in fc.lower():\n",
    "        print_flush(f\"[FC {idx}/{len(fcs)}] {fc} -> skipped (template)\")\n",
    "        continue\n",
    "\n",
    "    fc_path = os.path.join(gdb_path, RISKS_FDS, fc)\n",
    "    print_flush(f\"\\n[FC {idx}/{len(fcs)}] {fc} -> {fc_path}\")\n",
    "\n",
    "    # Find the matching risk column (holds target aliases directly)\n",
    "    risk_col = find_best_risk_column(fc, risk_cols_in_sheet)\n",
    "    if not risk_col:\n",
    "        print_flush(\"       ⚠ No matching risk column in Excel; skipping.\")\n",
    "        continue\n",
    "    print_flush(f\"       Matched risk column in Excel: '{risk_col}' (alias source)\")\n",
    "\n",
    "    # Select rows where the alias cell (this risk column) is non-empty\n",
    "    mask = df[risk_col].apply(is_truthy_cell)\n",
    "    sub = df.loc[mask, [field_col, decimals_col, comment_col, risk_col]].copy()\n",
    "    if sub.empty:\n",
    "        print_flush(\"       (No fields marked/aliased for this risk) → skip\")\n",
    "        continue\n",
    "\n",
    "    # Prepare per-field settings\n",
    "    sub.rename(columns={\n",
    "        field_col: \"field_name\",\n",
    "        decimals_col: \"decimals\",\n",
    "        comment_col: \"comment\",\n",
    "        risk_col: \"alias\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Clean up decimals (default to 2 if empty/invalid)\n",
    "    def parse_dec(v):\n",
    "        if pd.isna(v): \n",
    "            return 2\n",
    "        try:\n",
    "            n = int(float(str(v).replace(\",\", \".\")))\n",
    "            return max(0, min(10, n))  # clamp to a reasonable range\n",
    "        except Exception:\n",
    "            return 2\n",
    "    sub[\"decimals\"] = sub[\"decimals\"].apply(parse_dec)\n",
    "\n",
    "    # Determine which fields exist in the FC\n",
    "    try:\n",
    "        fields = arcpy.ListFields(fc_path)\n",
    "    except Exception as e:\n",
    "        print_flush(f\"       ✖ ERROR ListFields: {e}\")\n",
    "        continue\n",
    "\n",
    "    data_fields = [f for f in fields if f.type not in (\"OID\", \"Geometry\")]\n",
    "    present = {f.name for f in data_fields}\n",
    "\n",
    "    # Keep only fields present in the FC\n",
    "    sub = sub[sub[\"field_name\"].isin(present)].drop_duplicates(\"field_name\")\n",
    "    if sub.empty:\n",
    "        print_flush(\"       (Marked fields not present in this FC) → skip\")\n",
    "        continue\n",
    "\n",
    "    # Read only those fields\n",
    "    selected_fields = list(sub[\"field_name\"])\n",
    "    df_fc = featureclass_to_df(fc_path, selected_fields)\n",
    "\n",
    "    # Apply transforms per field, then rename to alias\n",
    "    # Build lookup dicts for speed\n",
    "    dec_map   = dict(zip(sub[\"field_name\"], sub[\"decimals\"]))\n",
    "    print(dec_map)\n",
    "    comm_map  = dict(zip(sub[\"field_name\"], sub[\"comment\"]))\n",
    "    alias_map = dict(zip(sub[\"field_name\"], sub[\"alias\"]))\n",
    "\n",
    "    SPECIAL_FIELDS = {\"iOverTot\", \"iOverLive\"}\n",
    "\n",
    "    for fld in selected_fields:\n",
    "        series = df_fc[fld]\n",
    "        s_num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        comment_text = str(comm_map.get(fld, \"\")).strip().lower()\n",
    "        nd = int(dec_map.get(fld, 2))  # per-field decimals\n",
    "\n",
    "        applied = False\n",
    "\n",
    "        # --- 1) 'gut' → no scaling/special, but DO round (and int if 0 d.p.) ---\n",
    "        if \"gut\" in comment_text:\n",
    "            if s_num.notna().any():\n",
    "                s_num = s_num.round(nd)\n",
    "                if nd == 0:\n",
    "                    try:\n",
    "                        s_num = s_num.astype(\"Int64\")  # nullable int keeps NaN\n",
    "                    except Exception:\n",
    "                        s_num = s_num.astype(float).astype(\"Int64\", errors=\"ignore\")\n",
    "                df_fc[fld] = s_num\n",
    "            # non-numeric stays untouched (but still renamed below)\n",
    "\n",
    "        else:\n",
    "            # --- 2) Special rule (highest priority) ---\n",
    "            if fld in SPECIAL_FIELDS and s_num.notna().any():\n",
    "                s_num = s_num * 100.0 - 100.0\n",
    "                applied = True\n",
    "\n",
    "            # --- 3) комментарий scaling (only if not special) ---\n",
    "            elif is_truthy_cell(comment_text) and s_num.notna().any():\n",
    "                clean = comment_text.replace(\" \", \"\")\n",
    "                if \"/1000000\" in clean:\n",
    "                    s_num = s_num / 1_000_000.0\n",
    "                elif \"%\" in clean or clean:\n",
    "                    s_num = s_num * 100.0\n",
    "                applied = True\n",
    "\n",
    "            # --- 4) Round everything numeric; int if 0 d.p. ---\n",
    "            if applied or s_num.notna().any():\n",
    "                s_num = s_num.round(nd)\n",
    "                if nd == 0:\n",
    "                    try:\n",
    "                        s_num = s_num.astype(\"Int64\")\n",
    "                    except Exception:\n",
    "                        s_num = s_num.astype(float).astype(\"Int64\", errors=\"ignore\")\n",
    "                df_fc[fld] = s_num\n",
    "\n",
    "            # # --- 6) Post-correction: ensure sLiveFrac >= sTotFrac ---\n",
    "            # if \"sLiveFrac\" in df_fc.columns and \"sTotFrac\" in df_fc.columns:\n",
    "            #     try:\n",
    "            #         # Work only on numeric values\n",
    "            #         s_live = pd.to_numeric(df_fc[\"sLiveFrac\"], errors=\"coerce\")\n",
    "            #         s_tot  = pd.to_numeric(df_fc[\"sTotFrac\"],  errors=\"coerce\")\n",
    "\n",
    "            #         # Replace where live < total\n",
    "            #         mask = s_live < s_tot\n",
    "            #         if mask.any():\n",
    "            #             df_fc.loc[mask, \"sLiveFrac\"] = s_tot[mask]\n",
    "            #             print_flush(f\"       Adjusted {mask.sum()} row(s): sLiveFrac < sTotFrac → set equal.\")\n",
    "            #     except Exception as e:\n",
    "            #         print_flush(f\"       ⚠ Error during sLiveFrac/sTotFrac correction: {e}\")\n",
    "\n",
    "        # --- 5) Rename to alias (always) ---\n",
    "        alias = str(alias_map.get(fld, fld)).strip()\n",
    "        if alias:\n",
    "            df_fc.rename(columns={fld: alias}, inplace=True)\n",
    "            \n",
    "\n",
    "    # Export CSV\n",
    "    out_name = f\"{region}_{fc}.csv\"\n",
    "    out_path = os.path.join(OUT_DIR, out_name)\n",
    "    df_fc.to_csv(out_path, index=False, encoding=ENCODING, sep = ';')\n",
    "    exported += 1\n",
    "    print_flush(f\"       ✔ Exported {df_fc.shape[0]} rows, {df_fc.shape[1]} cols -> {out_name}\")\n",
    "\n",
    "# ========= SUMMARY =========\n",
    "print_flush(f\"\\n[3/4] Exported CSVs: {exported}\")\n",
    "print_flush(f\"[4/4] Output folder: {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d048ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4] Reading Excel: C:\\Users\\User\\Documents\\ЦГД\\Структура базы_v03.xlsx (sheet='Поля для дашборда') ...\n",
      "       Rows: 112; Columns: ['Группа полей', 'Поле шейпа (10 симв., латынь)', 'Псевдоним (понятный, русский)', 'Размерность исходных данных', 'Псевдоним в дашборде', 'Wildfire', 'Cold', 'Heat', 'Rain', 'Wind', 'Freez', 'Hail', 'Thunderstorm', 'Drought', 'Flood', 'Permafrost', 'количество знаков после запятой', 'комментарий']\n",
      "[2/4] Creating FileGDB: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\n",
      "[3/4] Found 10 CSVs in C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\risk_csv\n",
      "\n",
      "[CSV 1/10] KHMAO_KHMAO_hazCold_MO.csv\n",
      "       Matched Excel risk column: 'Cold'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazCold_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazCold_MO\n",
      "\n",
      "[CSV 2/10] KHMAO_KHMAO_hazFlood_MO.csv\n",
      "       Matched Excel risk column: 'Flood'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazFlood_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazFlood_MO\n",
      "\n",
      "[CSV 3/10] KHMAO_KHMAO_hazFreez5_MO.csv\n",
      "       Matched Excel risk column: 'Freez'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazFreez5_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazFreez5_MO\n",
      "\n",
      "[CSV 4/10] KHMAO_KHMAO_hazHail_MO.csv\n",
      "       Matched Excel risk column: 'Hail'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazHail_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazHail_MO\n",
      "\n",
      "[CSV 5/10] KHMAO_KHMAO_hazHeat_MO.csv\n",
      "       Matched Excel risk column: 'Heat'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazHeat_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazHeat_MO\n",
      "\n",
      "[CSV 6/10] KHMAO_KHMAO_hazPermafrost_MO.csv\n",
      "       Matched Excel risk column: 'Permafrost'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazPermafrost_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazPermafrost_MO\n",
      "\n",
      "[CSV 7/10] KHMAO_KHMAO_hazRain_MO.csv\n",
      "       Matched Excel risk column: 'Rain'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazRain_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazRain_MO\n",
      "\n",
      "[CSV 8/10] KHMAO_KHMAO_hazThunderstorm_MO.csv\n",
      "       Matched Excel risk column: 'Thunderstorm'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazThunderstorm_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazThunderstorm_MO\n",
      "\n",
      "[CSV 9/10] KHMAO_KHMAO_hazWildfire_MO.csv\n",
      "       Matched Excel risk column: 'Wildfire'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazWildfire_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazWildfire_MO\n",
      "\n",
      "[CSV 10/10] KHMAO_KHMAO_hazWind_MO.csv\n",
      "       Matched Excel risk column: 'Wind'\n",
      "       Creating table: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\\KHMAO_hazWind_MO\n",
      "       ✔ Inserted 22 row(s) into KHMAO_hazWind_MO\n",
      "\n",
      "[4/4] DONE. New GDB created at: C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_CSV_Rebuild_20251031.gdb\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Rebuild a new GDB from per-risk CSVs (headers = aliases).\n",
    "- Map alias -> original field name via Excel ('Поля для дашборда') for matching risk.\n",
    "- Create FileGDB tables with only two field types: TEXT and LONG (ints).\n",
    "- Numeric values are rounded and stored as integers (LONG).\n",
    "- Field aliases are preserved from CSV headers.\n",
    "\n",
    "Requires: arcpy, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "# ========= CONFIG =========\n",
    "REGION         = \"KHMAO\"\n",
    "CSV_DIR        = r\"C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\\KHMAO_RiskProfile\\risk_csv\"    # folder with your CSVs\n",
    "EXCEL_PATH     = r\"C:\\Users\\User\\Documents\\ЦГД\\Структура базы_v03.xlsx\"\n",
    "SHEET_NAME     = \"Поля для дашборда\"\n",
    "OUT_GDB_DIR    = r\"C:\\Users\\User\\Documents\\ЦГД\\KHMAO_RiskProfile_28-10-2025\"\n",
    "OUT_GDB_NAME   = f\"{REGION}_CSV_Rebuild_20251031.gdb\"\n",
    "TABLE_PREFIX   = \"\"  # optional\n",
    "MAX_TEXT_LEN   = 255\n",
    "ENCODING       = \"utf-8-sig\"\n",
    "\n",
    "# ========= HELPERS =========\n",
    "def print_flush(*args, **kwargs):\n",
    "    print(*args, **kwargs); sys.stdout.flush()\n",
    "\n",
    "def secs(dt): return f\"{dt:.2f}s\"\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    return re.sub(r\"[_\\W]+\", \"\", str(s).strip().lower(), flags=re.UNICODE)\n",
    "\n",
    "def find_best_risk_column(fc_name: str, candidate_cols):\n",
    "    \"\"\"Exact (ci) → normalized equality → substring overlap.\"\"\"\n",
    "    fc_l = fc_name.strip(); fc_n = normalize(fc_l)\n",
    "    for c in candidate_cols:\n",
    "        if fc_l.lower() == str(c).strip().lower(): return c\n",
    "    for c in candidate_cols:\n",
    "        if fc_n == normalize(c): return c\n",
    "    best, best_len = None, 0\n",
    "    for c in candidate_cols:\n",
    "        cn = normalize(c)\n",
    "        if fc_n in cn or cn in fc_n:\n",
    "            L = min(len(fc_n), len(cn))\n",
    "            if L > best_len: best, best_len = c, L\n",
    "    return best\n",
    "\n",
    "def sanitize_table_name(name: str) -> str:\n",
    "    s = re.sub(r\"[^\\w]\", \"_\", name)\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    if not s: s = \"table\"\n",
    "    if not s[0].isalpha(): s = \"t_\" + s\n",
    "    return s[:64]\n",
    "\n",
    "def infer_text_or_int(series: pd.Series):\n",
    "    \"\"\"\n",
    "    Only TEXT or LONG.\n",
    "    If all (or mostly) values are numeric -> LONG.\n",
    "    Else TEXT.\n",
    "    \"\"\"\n",
    "    s_num = pd.to_numeric(series, errors=\"coerce\")\n",
    "    non_null = s_num.notna().sum()\n",
    "    if non_null > 0 and non_null >= 0.5 * len(series):\n",
    "        return \"LONG\"\n",
    "    return \"TEXT\"\n",
    "\n",
    "# ========= READ EXCEL =========\n",
    "t0 = time.time()\n",
    "print_flush(f\"[1/4] Reading Excel: {EXCEL_PATH} (sheet='{SHEET_NAME}') ...\")\n",
    "df_map = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME)\n",
    "print_flush(f\"       Rows: {len(df_map)}; Columns: {list(df_map.columns)}\")\n",
    "\n",
    "cols_lower = {str(c).strip().lower(): c for c in df_map.columns}\n",
    "FIELDNAME_HEADER = \"Поле шейпа (10 симв., латынь)\"\n",
    "field_col = cols_lower.get(FIELDNAME_HEADER.lower()) \\\n",
    "    or cols_lower.get(\"название поля\") or cols_lower.get(\"field_name_tot\") or cols_lower.get(\"имя поля\")\n",
    "if not field_col:\n",
    "    raise ValueError(\"Не найден столбец с именами полей ('Поле шейпа (10 симв., латынь)')\")\n",
    "\n",
    "df_map[field_col] = df_map[field_col].astype(str).str.strip()\n",
    "meta_cols = {field_col}\n",
    "risk_cols_in_sheet = [c for c in df_map.columns if c not in meta_cols]\n",
    "if not risk_cols_in_sheet:\n",
    "    raise RuntimeError(\"В листе нет столбцов с рисками (с алиасами).\")\n",
    "\n",
    "# ========= CREATE NEW GDB =========\n",
    "out_gdb_path = os.path.join(OUT_GDB_DIR, OUT_GDB_NAME)\n",
    "print_flush(f\"[2/4] Creating FileGDB: {out_gdb_path}\")\n",
    "if arcpy.Exists(out_gdb_path):\n",
    "    arcpy.management.Delete(out_gdb_path)\n",
    "arcpy.management.CreateFileGDB(OUT_GDB_DIR, OUT_GDB_NAME)\n",
    "\n",
    "# ========= PROCESS CSVs =========\n",
    "csv_files = sorted(Path(CSV_DIR).glob(\"*.csv\"))\n",
    "print_flush(f\"[3/4] Found {len(csv_files)} CSVs in {CSV_DIR}\")\n",
    "\n",
    "for idx, csv_path in enumerate(csv_files, start=1):\n",
    "    print_flush(f\"\\n[CSV {idx}/{len(csv_files)}] {csv_path.name}\")\n",
    "\n",
    "    # Read CSV\n",
    "    df_csv = pd.read_csv(csv_path, encoding=ENCODING, keep_default_na=True, dtype=str, sep=';')\n",
    "\n",
    "    # Deduce risk name (region stripped)\n",
    "    base = csv_path.stem\n",
    "    fc_name = base[len(f\"{REGION}_\"):] if base.startswith(f\"{REGION}_\") else base\n",
    "\n",
    "    # Match Excel risk column\n",
    "    risk_col = find_best_risk_column(fc_name, risk_cols_in_sheet)\n",
    "    if not risk_col:\n",
    "        print_flush(f\"       ⚠ No matching risk column in Excel for '{fc_name}'. Skipping.\")\n",
    "        continue\n",
    "    print_flush(f\"       Matched Excel risk column: '{risk_col}'\")\n",
    "\n",
    "    # Build alias → field name map\n",
    "    sub_map = df_map[[field_col, risk_col]].dropna().copy()\n",
    "    sub_map[risk_col] = sub_map[risk_col].astype(str).str.strip()\n",
    "    sub_map = sub_map[sub_map[risk_col] != \"\"]\n",
    "    alias_to_field = dict(zip(sub_map[risk_col], sub_map[field_col]))\n",
    "\n",
    "    # Map aliases to original names\n",
    "    field_aliases = list(df_csv.columns)\n",
    "    field_names = []\n",
    "    for alias in field_aliases:\n",
    "        orig = alias_to_field.get(alias)\n",
    "        if orig:\n",
    "            field_names.append(orig)\n",
    "        else:\n",
    "            safe = re.sub(r\"[^\\w]\", \"_\", alias).strip(\"_\")\n",
    "            if not safe: safe = \"fld\"\n",
    "            if not safe[0].isalpha(): safe = \"f_\" + safe\n",
    "            field_names.append(safe[:64])\n",
    "\n",
    "    # Create table\n",
    "    table_name = sanitize_table_name(TABLE_PREFIX + fc_name)\n",
    "    out_table = os.path.join(out_gdb_path, table_name)\n",
    "    print_flush(f\"       Creating table: {out_table}\")\n",
    "    arcpy.management.CreateTable(out_gdb_path, table_name)\n",
    "\n",
    "    # Determine types (TEXT or LONG)\n",
    "    field_types = []\n",
    "    for alias, fname in zip(field_aliases, field_names):\n",
    "        ser = df_csv[alias]\n",
    "        ftype = infer_text_or_int(ser)\n",
    "        field_types.append(ftype)\n",
    "        kwargs = {\n",
    "            \"in_table\": out_table,\n",
    "            \"field_name\": fname,\n",
    "            \"field_type\": ftype,\n",
    "            \"field_alias\": alias,\n",
    "            \"field_is_nullable\": \"NULLABLE\"\n",
    "        }\n",
    "        if ftype == \"TEXT\":\n",
    "            kwargs[\"field_length\"] = min(MAX_TEXT_LEN, int(max(df_csv[alias].astype(str).map(len).max(), 1)))\n",
    "        arcpy.management.AddField(**kwargs)\n",
    "\n",
    "    # Coerce and insert\n",
    "    insert_fields = field_names\n",
    "    with arcpy.da.InsertCursor(out_table, insert_fields) as cur:\n",
    "        for _, row in df_csv.iterrows():\n",
    "            vals = []\n",
    "            for alias, fname, ftype in zip(field_aliases, field_names, field_types):\n",
    "                val = row[alias]\n",
    "                if pd.isna(val) or str(val).strip() == \"\":\n",
    "                    vals.append(None)\n",
    "                    continue\n",
    "                if ftype == \"LONG\":\n",
    "                    try:\n",
    "                        num = float(str(val).replace(\",\", \".\"))\n",
    "                        vals.append(int(round(num)))\n",
    "                    except Exception:\n",
    "                        vals.append(None)\n",
    "                else:\n",
    "                    vals.append(str(val))\n",
    "            cur.insertRow(tuple(vals))\n",
    "\n",
    "    print_flush(f\"       ✔ Inserted {len(df_csv)} row(s) into {table_name}\")\n",
    "\n",
    "print_flush(f\"\\n[4/4] DONE. New GDB created at: {out_gdb_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcpro-clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
