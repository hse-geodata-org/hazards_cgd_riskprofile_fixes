{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b92d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4] Reading Excel: C:\\Users\\User\\Documents\\ЦГД\\Структура базы_v03.xlsx (sheet='Поля для дашборда') ...\n",
      "       Rows: 112; Columns: ['Группа полей', 'Поле шейпа (10 симв., латынь)', 'Псевдоним (понятный, русский)', 'Размерность исходных данных', 'Псевдоним в дашборде', 'Wildfire', 'Cold', 'Heat', 'Rain', 'Wind', 'Freez', 'Hail', 'Thunderstorm', 'Drought', 'Flood', 'Permafrost', 'количество знаков после запятой', 'комментарий']\n",
      "       Risk columns detected: 15\n",
      "\n",
      "[2/4] Feature dataset 'risk' -> 12 feature classes found\n",
      "[FC 1/12] Yakutia_hazardTemplate_MO -> skipped (template)\n",
      "\n",
      "[FC 2/12] Yakutia_hazHeat_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazHeat_MO\n",
      "       Matched risk column in Excel: 'Heat' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'ieMeanTot': 1, 'ieMeanLive': 1, 'ieMaxTot': 1, 'ieMaxLive': 1, 'itMeanTot': 1, 'itMeanLive': 1, 'iOverTot': 0, 'iOverLive': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 35 cols -> Yakutia_Yakutia_hazHeat_MO.csv\n",
      "\n",
      "[FC 3/12] Yakutia_hazFreez5_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazFreez5_MO\n",
      "       Matched risk column in Excel: 'Freez' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 23 cols -> Yakutia_Yakutia_hazFreez5_MO.csv\n",
      "\n",
      "[FC 4/12] Yakutia_hazDrought_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazDrought_MO\n",
      "       Matched risk column in Excel: 'Drought' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'itMeanTot': 1, 'itMeanLive': 1, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 29 cols -> Yakutia_Yakutia_hazDrought_MO.csv\n",
      "\n",
      "[FC 5/12] Yakutia_hazThunderstorm_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazThunderstorm_MO\n",
      "       Matched risk column in Excel: 'Thunderstorm' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rSiHA_fo': 0, 'rSF_fo': 0, 'rViHA_fo': 0, 'rVaR_fo': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 29 cols -> Yakutia_Yakutia_hazThunderstorm_MO.csv\n",
      "\n",
      "[FC 6/12] Yakutia_hazHail_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazHail_MO\n",
      "       Matched risk column in Excel: 'Hail' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 23 cols -> Yakutia_Yakutia_hazHail_MO.csv\n",
      "\n",
      "[FC 7/12] Yakutia_hazRain_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazRain_MO\n",
      "       Matched risk column in Excel: 'Rain' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'ieMeanTot': 1, 'ieMeanLive': 1, 'ieMaxTot': 1, 'ieMaxLive': 1, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 37 cols -> Yakutia_Yakutia_hazRain_MO.csv\n",
      "\n",
      "[FC 8/12] Yakutia_hazWind_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazWind_MO\n",
      "       Matched risk column in Excel: 'Wind' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'ieMeanTot': 1, 'ieMeanLive': 1, 'ieMaxTot': 1, 'ieMaxLive': 1, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rSiHA_fo': 0, 'rSF_fo': 0, 'rViHA_fo': 0, 'rVaR_fo': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 33 cols -> Yakutia_Yakutia_hazWind_MO.csv\n",
      "\n",
      "[FC 9/12] Yakutia_hazCold_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazCold_MO\n",
      "       Matched risk column in Excel: 'Cold' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'ieMeanTot': 1, 'ieMeanLive': 1, 'ieMaxTot': 1, 'ieMaxLive': 1, 'itMeanTot': 1, 'itMeanLive': 1, 'iOverTot': 0, 'iOverLive': 0, 'fdMeanTot': 0, 'fdMeanLive': 0, 'fdMaxTot': 0, 'fdMaxLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rLiHA_ro': 0, 'rLF_ro': 0, 'rViHA_ro': 0, 'rVaR_ro': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 41 cols -> Yakutia_Yakutia_hazCold_MO.csv\n",
      "\n",
      "[FC 10/12] Yakutia_hazFlood_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazFlood_MO\n",
      "       Matched risk column in Excel: 'Flood' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'hNormTot': 2, 'hNormLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rLiHA_ro': 0, 'rLF_ro': 0, 'rViHA_ro': 0, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rNiHA_pop': 0, 'rNF_pop': 0}\n",
      "       ✔ Exported 36 rows, 21 cols -> Yakutia_Yakutia_hazFlood_MO.csv\n",
      "\n",
      "[FC 11/12] Yakutia_hazPermafrost_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazPermafrost_MO\n",
      "       Matched risk column in Excel: 'Permafrost' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'spTot': 0, 'spTotFrac': 0, 'spLive': 0, 'spLiveFrac': 0, 'itMeanTot': 1, 'itMeanLive': 1, 'hFxSTot': 1, 'hFxSLive': 1, 'hNormTot': 2, 'hExpertTot': 2, 'hNormLive': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rLiHA_ro': 0, 'rLF_ro': 0, 'rViHA_ro': 0, 'rVaR_ro': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 31 cols -> Yakutia_Yakutia_hazPermafrost_MO.csv\n",
      "\n",
      "[FC 12/12] Yakutia_hazWildfire_MO -> C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\\risk\\Yakutia_hazWildfire_MO\n",
      "       Matched risk column in Excel: 'Wildfire' (alias source)\n",
      "{'MO': 2, 'areaLiveF': 0, 'sTot': 0, 'sTotFrac': 0, 'sLive': 0, 'sLiveFrac': 0, 'itMeanTot': 1, 'itMeanLive': 1, 'feMeanTot': 0, 'feMeanLive': 0, 'hFxSTot': 1, 'hFxSLive': 1, 'hExpertTot': 2, 'hExpertLive': 2, 'rNiNA_ho': 0, 'rNF_ho': 0, 'rSiHA_ho': 0, 'rSF_ho': 0, 'rViHA_ho': 0, 'rVaR_ho': 0, 'rSiHA_ag': 0, 'rSF_ag': 0, 'rViHA_ag': 0, 'rVaR_ag': 0, 'rSiHA_fo': 0, 'rSF_fo': 0, 'rViHA_fo': 0, 'rVaR_fo': 0, 'rNiHA_pop': 0, 'rNF_pop': 0, 'rNaR_pop': 0}\n",
      "       ✔ Exported 36 rows, 31 cols -> Yakutia_Yakutia_hazWildfire_MO.csv\n",
      "\n",
      "[3/4] Exported CSVs: 11\n",
      "[4/4] Output folder: C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\risk_csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Export risk feature classes to CSV with per-field aliases and numeric transforms.\n",
    "\n",
    "For each FC in <gdb>\\risk:\n",
    "  - Map FC to a risk column in sheet 'Поля для дашборда'\n",
    "  - Keep rows where that risk column is non-empty; the cell is the TARGET ALIAS\n",
    "  - Read only those fields from the FC (no geometry)\n",
    "  - Per field:\n",
    "      * If Excel 'комментарий' cell is non-empty -> multiply by 100\n",
    "      * If field is iOverTot or iOverLive -> value = value*100 - 100\n",
    "      * Round to N decimals from Excel column 'количество знаков после запятой'\n",
    "  - Rename to alias and export CSV\n",
    "\n",
    "Requires: arcpy, pandas, openpyxl\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "# ========= CONFIGURE =========\n",
    "region     = \"Yakutia\"\n",
    "gdb_path   = r\"C:\\Users\\User\\Documents\\ЦГД\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile_30-10-2025\\Yakutia_RiskProfile\\Default.gdb\"\n",
    "RISKS_FDS  = \"risk\"\n",
    "EXCEL_PATH = r\"C:\\Users\\User\\Documents\\ЦГД\\Структура базы_v03.xlsx\"   # or the updated \"(1).xlsx\"\n",
    "SHEET_NAME = \"Поля для дашборда\"\n",
    "OUT_DIR    = os.path.join(os.path.dirname(gdb_path), \"risk_csv\")\n",
    "ENCODING   = \"utf-8-sig\"\n",
    "\n",
    "# Exact column headers (with robust fallbacks)\n",
    "FIELDNAME_HEADER   = \"Поле шейпа (10 симв., латынь)\"\n",
    "DECIMALS_HEADER    = \"количество знаков после запятой\"\n",
    "COMMENT_HEADER     = \"комментарий\"\n",
    "\n",
    "# ========= HELPERS =========\n",
    "def print_flush(*args, **kwargs):\n",
    "    print(*args, **kwargs); sys.stdout.flush()\n",
    "\n",
    "def secs(dt): return f\"{dt:.2f}s\"\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    return re.sub(r\"[_\\W]+\", \"\", str(s).strip().lower(), flags=re.UNICODE)\n",
    "\n",
    "def is_truthy_cell(v) -> bool:\n",
    "    if pd.isna(v): return False\n",
    "    if isinstance(v, (int, float)):\n",
    "        try: return float(v) != 0.0\n",
    "        except Exception: return True\n",
    "    s = str(v).strip()\n",
    "    return len(s) > 0 and s not in {\"0\", \"нет\", \"no\", \"false\", \"False\", \"-\"}\n",
    "\n",
    "def find_best_risk_column(fc_name: str, candidate_cols):\n",
    "    \"\"\"Exact (ci) → normalized equality → substring overlap.\"\"\"\n",
    "    fc_l = fc_name.strip()\n",
    "    fc_n = normalize(fc_l)\n",
    "\n",
    "    for c in candidate_cols:\n",
    "        if fc_l.lower() == str(c).strip().lower():\n",
    "            return c\n",
    "    for c in candidate_cols:\n",
    "        if fc_n == normalize(c):\n",
    "            return c\n",
    "    best, best_len = None, 0\n",
    "    for c in candidate_cols:\n",
    "        cn = normalize(c)\n",
    "        if fc_n in cn or cn in fc_n:\n",
    "            L = min(len(fc_n), len(cn))\n",
    "            if L > best_len:\n",
    "                best, best_len = c, L\n",
    "    return best\n",
    "\n",
    "def featureclass_to_df(fc_path: str, fields: list) -> pd.DataFrame:\n",
    "    \"\"\"Use SearchCursor so NULLs stay as None (avoids NumPy dtype issues).\"\"\"\n",
    "    if not fields:\n",
    "        return pd.DataFrame()\n",
    "    rows = []\n",
    "    with arcpy.da.SearchCursor(fc_path, fields) as cur:\n",
    "        for row in cur:\n",
    "            rows.append(row)\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=fields)\n",
    "    return pd.DataFrame.from_records(rows, columns=fields)\n",
    "\n",
    "# ========= READ EXCEL =========\n",
    "t0 = time.time()\n",
    "print_flush(f\"[1/4] Reading Excel: {EXCEL_PATH} (sheet='{SHEET_NAME}') ...\")\n",
    "df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME)\n",
    "print_flush(f\"       Rows: {len(df)}; Columns: {list(df.columns)}\")\n",
    "\n",
    "# Robust header resolution\n",
    "cols_lower = {str(c).strip().lower(): c for c in df.columns}\n",
    "\n",
    "def pick(colname, *fallbacks):\n",
    "    c = cols_lower.get(colname.strip().lower())\n",
    "    if c: return c\n",
    "    for fb in fallbacks:\n",
    "        cc = cols_lower.get(fb.strip().lower())\n",
    "        if cc: return cc\n",
    "    raise ValueError(f\"Не найден столбец: '{colname}' (с учетом возможных вариантов: {fallbacks})\")\n",
    "\n",
    "field_col    = cols_lower.get(FIELDNAME_HEADER.lower()) or pick(FIELDNAME_HEADER, \"название поля\", \"field_name_tot\", \"имя поля\")\n",
    "decimals_col = cols_lower.get(DECIMALS_HEADER.lower())  or pick(DECIMALS_HEADER, \"знаков после запятой\", \"decimal places\")\n",
    "comment_col  = cols_lower.get(COMMENT_HEADER.lower())   or pick(COMMENT_HEADER, \"коммент\", \"comment\")\n",
    "\n",
    "# Normalize core columns\n",
    "df[field_col]    = df[field_col].astype(str).str.strip()\n",
    "# decimals may be numeric or text; keep as-is for now\n",
    "# comment stays as-is; presence indicates x100\n",
    "\n",
    "# Risk columns are *everything else* (each cell holds the ALIAS to use)\n",
    "meta_cols = {field_col, decimals_col, comment_col}\n",
    "risk_cols_in_sheet = [c for c in df.columns if c not in meta_cols]\n",
    "if not risk_cols_in_sheet:\n",
    "    raise RuntimeError(\"В листе не обнаружены столбцы с рисками (кроме полей, знаков и комментариев).\")\n",
    "print_flush(f\"       Risk columns detected: {len(risk_cols_in_sheet)}\")\n",
    "\n",
    "# ========= SCAN GDB / EXPORT =========\n",
    "arcpy.env.workspace = os.path.join(gdb_path, RISKS_FDS)\n",
    "fcs = arcpy.ListFeatureClasses() or []\n",
    "print_flush(f\"\\n[2/4] Feature dataset '{RISKS_FDS}' -> {len(fcs)} feature classes found\")\n",
    "\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "exported = 0\n",
    "for idx, fc in enumerate(fcs, start=1):\n",
    "    if \"template\" in fc.lower():\n",
    "        print_flush(f\"[FC {idx}/{len(fcs)}] {fc} -> skipped (template)\")\n",
    "        continue\n",
    "\n",
    "    fc_path = os.path.join(gdb_path, RISKS_FDS, fc)\n",
    "    print_flush(f\"\\n[FC {idx}/{len(fcs)}] {fc} -> {fc_path}\")\n",
    "\n",
    "    # Find the matching risk column (holds target aliases directly)\n",
    "    risk_col = find_best_risk_column(fc, risk_cols_in_sheet)\n",
    "    if not risk_col:\n",
    "        print_flush(\"       ⚠ No matching risk column in Excel; skipping.\")\n",
    "        continue\n",
    "    print_flush(f\"       Matched risk column in Excel: '{risk_col}' (alias source)\")\n",
    "\n",
    "    # Select rows where the alias cell (this risk column) is non-empty\n",
    "    mask = df[risk_col].apply(is_truthy_cell)\n",
    "    sub = df.loc[mask, [field_col, decimals_col, comment_col, risk_col]].copy()\n",
    "    if sub.empty:\n",
    "        print_flush(\"       (No fields marked/aliased for this risk) → skip\")\n",
    "        continue\n",
    "\n",
    "    # Prepare per-field settings\n",
    "    sub.rename(columns={\n",
    "        field_col: \"field_name\",\n",
    "        decimals_col: \"decimals\",\n",
    "        comment_col: \"comment\",\n",
    "        risk_col: \"alias\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Clean up decimals (default to 2 if empty/invalid)\n",
    "    def parse_dec(v):\n",
    "        if pd.isna(v): \n",
    "            return 2\n",
    "        try:\n",
    "            n = int(float(str(v).replace(\",\", \".\")))\n",
    "            return max(0, min(10, n))  # clamp to a reasonable range\n",
    "        except Exception:\n",
    "            return 2\n",
    "    sub[\"decimals\"] = sub[\"decimals\"].apply(parse_dec)\n",
    "\n",
    "    # Determine which fields exist in the FC\n",
    "    try:\n",
    "        fields = arcpy.ListFields(fc_path)\n",
    "    except Exception as e:\n",
    "        print_flush(f\"       ✖ ERROR ListFields: {e}\")\n",
    "        continue\n",
    "\n",
    "    data_fields = [f for f in fields if f.type not in (\"OID\", \"Geometry\")]\n",
    "    present = {f.name for f in data_fields}\n",
    "\n",
    "    # Keep only fields present in the FC\n",
    "    sub = sub[sub[\"field_name\"].isin(present)].drop_duplicates(\"field_name\")\n",
    "    if sub.empty:\n",
    "        print_flush(\"       (Marked fields not present in this FC) → skip\")\n",
    "        continue\n",
    "\n",
    "    # Read only those fields\n",
    "    selected_fields = list(sub[\"field_name\"])\n",
    "    df_fc = featureclass_to_df(fc_path, selected_fields)\n",
    "\n",
    "    # Apply transforms per field, then rename to alias\n",
    "    # Build lookup dicts for speed\n",
    "    dec_map   = dict(zip(sub[\"field_name\"], sub[\"decimals\"]))\n",
    "    print(dec_map)\n",
    "    comm_map  = dict(zip(sub[\"field_name\"], sub[\"comment\"]))\n",
    "    alias_map = dict(zip(sub[\"field_name\"], sub[\"alias\"]))\n",
    "\n",
    "    SPECIAL_FIELDS = {\"iOverTot\", \"iOverLive\"}\n",
    "\n",
    "    for fld in selected_fields:\n",
    "        series = df_fc[fld]\n",
    "        s_num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        comment_text = str(comm_map.get(fld, \"\")).strip().lower()\n",
    "        nd = int(dec_map.get(fld, 2))  # per-field decimals\n",
    "\n",
    "        applied = False\n",
    "\n",
    "        # --- 1) 'gut' → no scaling/special, but DO round (and int if 0 d.p.) ---\n",
    "        if \"gut\" in comment_text:\n",
    "            if s_num.notna().any():\n",
    "                s_num = s_num.round(nd)\n",
    "                if nd == 0:\n",
    "                    try:\n",
    "                        s_num = s_num.astype(\"Int64\")  # nullable int keeps NaN\n",
    "                    except Exception:\n",
    "                        s_num = s_num.astype(float).astype(\"Int64\", errors=\"ignore\")\n",
    "                df_fc[fld] = s_num\n",
    "            # non-numeric stays untouched (but still renamed below)\n",
    "\n",
    "        else:\n",
    "            # --- 2) Special rule (highest priority) ---\n",
    "            if fld in SPECIAL_FIELDS and s_num.notna().any():\n",
    "                s_num = s_num * 100.0 - 100.0\n",
    "                applied = True\n",
    "\n",
    "            # --- 3) комментарий scaling (only if not special) ---\n",
    "            elif is_truthy_cell(comment_text) and s_num.notna().any():\n",
    "                clean = comment_text.replace(\" \", \"\")\n",
    "                if \"/1000000\" in clean:\n",
    "                    s_num = s_num / 1_000_000.0\n",
    "                elif \"%\" in clean or clean:\n",
    "                    s_num = s_num * 100.0\n",
    "                applied = True\n",
    "\n",
    "            # --- 4) Round everything numeric; int if 0 d.p. ---\n",
    "            if applied or s_num.notna().any():\n",
    "                s_num = s_num.round(nd)\n",
    "                if nd == 0:\n",
    "                    try:\n",
    "                        s_num = s_num.astype(\"Int64\")\n",
    "                    except Exception:\n",
    "                        s_num = s_num.astype(float).astype(\"Int64\", errors=\"ignore\")\n",
    "                df_fc[fld] = s_num\n",
    "\n",
    "            # # --- 6) Post-correction: ensure sLiveFrac >= sTotFrac ---\n",
    "            # if \"sLiveFrac\" in df_fc.columns and \"sTotFrac\" in df_fc.columns:\n",
    "            #     try:\n",
    "            #         # Work only on numeric values\n",
    "            #         s_live = pd.to_numeric(df_fc[\"sLiveFrac\"], errors=\"coerce\")\n",
    "            #         s_tot  = pd.to_numeric(df_fc[\"sTotFrac\"],  errors=\"coerce\")\n",
    "\n",
    "            #         # Replace where live < total\n",
    "            #         mask = s_live < s_tot\n",
    "            #         if mask.any():\n",
    "            #             df_fc.loc[mask, \"sLiveFrac\"] = s_tot[mask]\n",
    "            #             print_flush(f\"       Adjusted {mask.sum()} row(s): sLiveFrac < sTotFrac → set equal.\")\n",
    "            #     except Exception as e:\n",
    "            #         print_flush(f\"       ⚠ Error during sLiveFrac/sTotFrac correction: {e}\")\n",
    "\n",
    "        # --- 5) Rename to alias (always) ---\n",
    "        alias = str(alias_map.get(fld, fld)).strip()\n",
    "        if alias:\n",
    "            df_fc.rename(columns={fld: alias}, inplace=True)\n",
    "            \n",
    "\n",
    "    # Export CSV\n",
    "    out_name = f\"{region}_{fc}.csv\"\n",
    "    out_path = os.path.join(OUT_DIR, out_name)\n",
    "    df_fc.to_csv(out_path, index=False, encoding=ENCODING, sep = ';')\n",
    "    exported += 1\n",
    "    print_flush(f\"       ✔ Exported {df_fc.shape[0]} rows, {df_fc.shape[1]} cols -> {out_name}\")\n",
    "\n",
    "# ========= SUMMARY =========\n",
    "print_flush(f\"\\n[3/4] Exported CSVs: {exported}\")\n",
    "print_flush(f\"[4/4] Output folder: {OUT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcpro-clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
